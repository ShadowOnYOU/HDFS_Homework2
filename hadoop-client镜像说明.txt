hadoop-client镜像使用说明
Hadoop 客户端 Docker/Podman 配置
这个 Docker/Podman 配置提供了一个完整的 Hadoop 客户端环境，可以连接到远程 Hadoop 集群。
容器引擎选择
本配置支持 Docker 和 Podman 两种容器引擎，命令基本相同可以相互替换。
注意事项：
●由于 Hadoop 在集群内网，如果你人不在学校需要使用 EasyConnect 代理，这可能导致本地容器无法访问到 Hadoop 集群。
●为了解决这个问题，可以在学院的服务器上安装 Docker 或 Podman，然后在服务器上运行容器，本地 IDE 连接到服务器进行开发。
安装方式
Podman 安装: https://podman.io/docs/installation 
Docker 安装: https://docs.docker.com/desktop/ 
注意: Docker 和 Podman 的命令语法基本相同，您可以根据需要选择使用其中任意一种。
镜像仓库地址
镜像仓库地址: registry.cn-hangzhou.aliyuncs.com/mydocker_he/hadoop-client
快速开始
用户信息
●用户名: hadoop
●密码: hadoop
●权限: hadoop 用户已添加到 sudo 组，具有管理员权限
1. 拉取镜像

# 拉取 Hadoop 客户端镜像（支持 Docker 和 Podman）
docker pull registry.cn-hangzhou.aliyuncs.com/mydocker_he/hadoop-client

# mac用户需要拉arm64镜像
docker pull registry.cn-hangzhou.aliyuncs.com/mydocker_he/hadoop-client:arm64


# 或者使用 Podman
podman pull registry.cn-hangzhou.aliyuncs.com/mydocker_he/hadoop-client

2. 运行前准备
在运行容器之前，请确保在宿主机上创建以下目录（用于容器 Volume 挂载）：
Linux/MacOS 平台

# 创建 java_code 目录（用于 Java 代码开发）
mkdir -p <YOUR_HOST_PATH>/java_code

Windows 平台
# 创建 java_code 目录（用于 Java 代码开发）
mkdir <YOUR_HOST_PATH>\java_code



> 注意: 请将 `<YOUR_HOST_PATH>` 替换为您本地的实际路径，例如：
/home/hadoop/bigdata/hw2/java_code


3. 运行客户端容器
Linux/MacOS 平台:

# 后台运行 Hadoop 客户端容器
docker run -d --name hadoop-client \
  -p 9000:9000 -p 9870:9870 -p 8032:8032 -p 8088:8088 -p 19888:19888 \
  -v <YOUR_HOST_PATH>/java_code:/home/hadoop/java_code \
  --add-host hadoop-master:172.19.240.155 \
  --add-host hadoop-worker1:172.19.240.129 \
  --add-host hadoop-worker2:172.19.241.168 \
  --add-host hadoop-worker3:172.19.241.70 \
  --add-host hadoop-worker4:172.19.241.153 \
  --cap-add=NET_RAW --cap-add=NET_ADMIN \
  hadoop-client tail -f /dev/null



Windows 平台：

docker run -d --name hadoop-client `
  -p 9000:9000 -p 9870:9870 -p 8032:8032 -p 8088:8088 -p 19888:19888 `
  -v <YOUR_HOST_PATH>/java_code:/home/hadoop/java_code `
  --add-host hadoop-master:172.19.240.155 `
  --add-host hadoop-worker1:172.19.240.129 `
  --add-host hadoop-worker2:172.19.241.168 `
  --add-host hadoop-worker3:172.19.241.70 `
  --add-host hadoop-worker4:172.19.241.153 `
  --cap-add=NET_RAW --cap-add=NET_ADMIN `
  hadoop-client tail -f /dev/null

占位符说明: 请将 <YOUR_HOST_PATH> 替换为您本地的实际路径，例如：/home/hadoop/bigdata/hw2/java_code
网络权限说明: --cap-add=NET_RAW --cap-add=NET_ADMIN 参数用于启用网络工具（如 ping、traceroute 等）的权限，确保容器内的网络诊断功能正常工作。
4. 进入运行中的容器

# 进入容器（Docker）
docker exec -it hadoop-client bash

# 进入容器（Podman）
podman exec -it hadoop-client bash

5. 容器管理命令

# 查看运行中的容器
docker ps
# 或者
podman ps

# 查看所有容器
docker ps -a
# 或者
podman ps -a

# 停止容器
docker stop hadoop-client
# 或者
podman stop hadoop-client

# 启动已停止的容器
docker start hadoop-client
# 或者
podman start hadoop-client

# 删除容器
docker rm hadoop-client
# 或者
podman rm hadoop-client

# 查看容器日志
docker logs hadoop-client
# 或者
podman logs hadoop-client

6.配置环境变量
# clone git仓库
git clone https://github.com/ForceInjection/Big-Data-Theory-and-Practice.git

cd Big-Data-Theory-and-Practice

# 执行配置脚本
bash env-setup/multi-node/cluster-setup-scripts/05-setup_student_client.sh

# 查看环境变量
echo $HADOOP_USER_NAME
# s<学号>

echo $HADOOP_MAPRED_QUEUE_NAME
# students


7.测试集群连接

# 手动测试网络连接
ping hadoop-master

# 测试 HDFS 连接
hdfs dfs -ls /

# 测试 YARN 集群状态
yarn node -list

# 查看用户目录（确保使用正确的学号格式，如 s2024001）
hdfs dfs -ls /users/s2024001
# 提交hadoop官方提供的MapReduce示例hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar wordcount /public/data/wordcount/simple-test.txt /users/s<学号>/output/test-$(date +%Y%m%d-%H%M%S)

手动配置（可选）
如果需要手动配置 Hadoop，可以编辑配置文件：

# 编辑核心配置文件
vim $HADOOP_CONF_DIR/core-site.xml
vim $HADOOP_CONF_DIR/hdfs-site.xml
vim $HADOOP_CONF_DIR/yarn-site.xml
vim $HADOOP_CONF_DIR/mapred-site.xml

# 示例：配置 core-site.xml
 cat > $HADOOP_CONF_DIR/core-site.xml << EOF
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop-master:9000</value>
    </property>
</configuration>
EOF

端口映射
容器暴露了以下端口：
●9000: HDFS 文件系统访问
●9870: NameNode Web UI
●8032: ResourceManager 服务
●8088: ResourceManager Web UI
●19888: JobHistory Web UI
常用命令
HDFS 操作

# 查看 HDFS 根目录
hdfs dfs -ls /

# 创建用户目录
hdfs dfs -mkdir -p /user/hadoop

# 上传文件
hdfs dfs -put localfile.txt /user/hadoop/

# 下载文件
hdfs dfs -get /user/hadoop/remotefile.txt localfile.txt

# 查看文件内容
hdfs dfs -cat /user/hadoop/file.txt

作业提交

# 运行 WordCount 示例
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar \
    wordcount \
    /public/data/wordcount/simple-test.txt \
    /users/s<学号>/output/wordcount-$(date +%Y%m%d-%H%M%S)

# 查看作业结果
hdfs dfs -cat /users/s<学号>/output/wordcount-*/part-r-00000

MapReduce 作业历史

# 查看作业历史
mapred job -list

# 查看特定作业详情
mapred job -status job_id

数据持久化
容器挂载了以下本地目录（请将 <YOUR_HOST_PATH> 替换为您的实际路径）：
●<YOUR_HOST_PATH>/hadoop: Hadoop 数据和配置目录
○映射到容器内的 /home/hadoop/hadoop
○用于持久化存储 Hadoop 相关数据和配置文件
●<YOUR_HOST_PATH>/cluster-setup-scripts: 集群配置脚本目录
○映射到容器内的 /home/hadoop/cluster-setup-scripts
○便于在宿主机上修改脚本，无需重新构建镜像
○脚本修改后立即在容器中生效
●<YOUR_HOST_PATH>/java_code: Java 代码目录
○映射到容器内的 /home/hadoop/java_code
○用于开发和测试 Java MapReduce 程序
○支持在宿主机上编写代码，在容器中编译和运行
镜像管理

# 查看镜像
docker images
# 或者
podman images

# 删除镜像
docker rmi hadoop-client
# 或者
podman rmi hadoop-client

故障排除
Windows + Docker Desktop出现可以ping通外网但是ping不通内网

解决方法：
1.换到Linux环境，如本地Linux系统或学院的服务器
2.在WSL中安装docker进行实验 :
sudo apt install docker.io


网络连接问题
如果无法连接到集群：
1.检查网络连接：

ping hadoop-master

2.检查端口连通性：

nc -zv hadoop-master 9000
nc -zv hadoop-master 9870

3.检查防火墙设置
权限问题
如果遇到权限问题：

# 确保使用 hadoop 用户
whoami

# 检查 HDFS 权限
hdfs dfs -ls /

配置问题
如果配置不正确：

# 检查配置文件
cat $HADOOP_CONF_DIR/core-site.xml

# 验证配置
hdfs getconf -confKey fs.defaultFS

注意事项
1.容器引擎选择: Docker 和 Podman 命令基本相同，可以互换使用
2.路径替换: 请将命令中的 <YOUR_HOST_PATH> 替换为您的实际宿主机路径
3.配置方式: 最新镜像采用手动配置方式，没有预置快速配置脚本
4.网络配置: 确保宿主机的 /etc/hosts 文件或等效的 DNS 配置正确

